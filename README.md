# GPU 集群资源调度算法

综合多种调度算法给出分布式深度学习多作业在 GPU 集群上的调度次序以及资源分配方案，令作业总体完成时间尽可能小，资源利用率尽可能高。

## 调度算法

- 顺序调度
- 并行调度
- Optimus 调度
- 遗传算法调度(不考虑利用时间片)
- 遗传算法调度(考虑利用时间片)

## 调度过程

分别选取图片分类和动作识别两个领域的多个模型，记录在多个 GPU 上的单轮迭代时间，进而得到模型训练完成时间。

调度算法根据每个模型的完成时间，给出每个作业的调度次序以及资源分配方案。

## 启动方式

使用 sql 目录下的脚本文件创建对应数据表，记录模型批次大小、迭代次数、GPU 个数、迭代时间等信息。

在命令行模式下，使用命令`python main.py`启动调度过程。

## 有关分布式训练导致的精度损失问题

这是因为在分布式训练场景下，随着分配 GPU 数量的增加，整体数据的吞吐量也会上升，但是模型学习率却没有跟着进行变化，导致模型精度下降。

一个解决方法就是让学习率随着 GPU 数量成比例增加，或者逐渐增加至某个值后便不再变化。

参考论文：[Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour](https://arxiv.org/abs/1706.02677)
